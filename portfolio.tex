\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Software Testing 2025/6 Portfolio}
\author{Zoran Ma}

\begin{document}
\maketitle

\section{Outline of the Software Being Tested}
For this coursework, I am testing my ILP project called \textbf{PizzaDrone}. It is a Java Spring Boot application designed to help drones deliver pizzas to students in Appleton Tower. The system has two main jobs: (1) it validates orders to make sure they follow business rules (like checking if the restaurant is open), and (2) it efficiently calculates the shortest flight path for the drone, making sure to avoid "No-Fly Zones".

\section{Learning Outcomes}
\begin{enumerate}
\item \textbf{Analyze requirements to determine appropriate testing strategies} \marginpar{[default 20\%]}

\begin{enumerate}
\item \textbf{Range of requirements, functional requirements, measurable quality attributes, qualitative requirements}

Full details are in \texttt{docs/requirements.md}. I derived requirements by considering \textbf{Stakeholders} (e.g., Students, University Admin, Drone Operators).
\textbf{Functional:} I distinguished between \textbf{Correctness properties} (ensuring order logic produces correct results, FR1--FR6) and \textbf{Safety properties} (ensuring the system \textit{cannot} violate safety rules like entering No-Fly Zones, FR9).
\textbf{Qualitative (QR1--QR4):} Ensured the system is data-driven (fetching external APIs), robust against malformed JSON, and meets the 60s performance target.

\item \textbf{Level of requirements, system, integration, unit}

As detailed within \texttt{requirements.md}, I structured requirements to be tested at three distinct levels. I targeted the Unit Level for isolating complex algorithmic logic (e.g., distance checks) and strict validation rules (FR1--FR6). I addressed the Integration Level to verify that the \texttt{OrderService} correctly orchestrates internal logic with data fetched from external providers (QR1). Also, I covered the System Level by treating the application as a black box to verify the REST API contract and HTTP status codes (FR12--FR14).


\item \textbf{Identifying test approach for chosen attributes}
To verify the attributes mapped in \texttt{requirements.md}. I used \textit{JUnit 5} tests to efficiently cover the edge cases of validation rules (FR1-FR6). To handle the dependency on the external ILP service (QR1), I used \textit{Mockito} to simulate external responses. This ensures test determinism and allows simulation of "dirty data" without relying on the unstable live environment. For API verification, I utilized \textit{MockMvc} for HTTP testing, while performance constraints (QR4) were enforced using strictly defined JUnit timeouts.

\item \textbf{Assess the appropriateness of your chosen testing approach}
This strategy effectively maximizes Verification given the project constraints. Mocking is appropriate to avoid "flaky tests" caused by external service instability.
However, a key limitation is the difficulty of performing validation under realistic conditions. My approach relies on mocks rather than live data, which means I cannot fully validate system behaviour against real-world network latency or silent API schema changes.

\end{enumerate}
\item \textbf{Design and implement comprehensive test plans with instrumented code} \marginpar{[default 20\%]}
\begin{enumerate}
\item \textbf{Construction of the test plan}

A test plan is detailed in \texttt{docs/test\_planning.md}. It adopts an **Extreme Programming (XP)** "Test-First" workflow for development and a **DevOps** lifecycle for verification. This ensures that unit tests precede implementation (TDD) and integration testing is automated via a CI pipeline.

\item \textbf{Evaluation of the quality of the test plan}

The plan's evaluation (see \texttt{TEST\_PLAN.md} Section 1) prioritizes testing based on **Safety** (P1) and **Revenue** (P1) risks. It acknowledges schedule risks, mitigated by the XP "TestFrom" approach, and technology risks regarding \texttt{MockMvc}, mitigated by early scaffolding. Security testing was identified as an omission due to constraints.

\item \textbf{Instrumentation of the code}

Instrumentation and Scaffolding are defined in Section 2. I implemented \textbf{SLF4J logging} to trace specific validation failure codes (e.g., distinguishing \texttt{CVV\_INVALID} from \texttt{CARD\_NUMBER\_INVALID}). For scaffolding, I used \textbf{Mockito} to isolate the system from unstable external APIs and \textbf{MockMvc} as a headless driver.

\item \textbf{Evaluation of the instrumentation}

The current instrumentation is highly effective for debugging logical flows and verifying correct failure reasons, as shown by the distinct log entries for different validation errors. The addition of JUnit \texttt{@Timeout} annotations ensures the 60-second performance requirement is strictly enforced by the test runner itself.

\end{enumerate}

\item \textbf{Apply a wide variety of testing techniques and compute test coverage and yield according to a variety of criteria} \marginpar{[default 20\%]}
\begin{enumerate}
\item\textbf{Range of techniques}
\item\textbf{Evaluation criteria for the adequacy of the testing}
\item \textbf{Results of testing}
\item \textbf{Evaluation of the results}
\end{enumerate}

\item \textbf{Evaluate the limitations of a given testing process, using statistical methods where appropriate, and summarise outcomes} \marginpar{[default 20\%]}
\begin{enumerate}
\item \textbf{Identifying gaps and omissions in the testing process}
\item \textbf{Identifying target coverage/performance levels for the different testing procedures} 
\item \textbf{Discussing how the testing carried out compares with the target levels}
\item \textbf{Discussion of what would be necessary to achieve the target level}
\end{enumerate}

\item \textbf{Conduct reviews, inspections, and design and implement automated testing processes} \marginpar{[default 20\%]}
\begin{enumerate}    
\item \textbf{Identify and apply review criteria to selected parts of the code and identify issues in the code}
\item \textbf{Construct an appropriate CI pipeline for the software}
\item\textbf{Automate some aspects of the testing}
\item \textbf{Demonstrate the CI pipeline functions as expected}
\end{enumerate}

\end{enumerate}
\end{document}